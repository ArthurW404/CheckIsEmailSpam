{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get and check Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0  0.64  0.64.1  0.1  0.32   0.2   0.3   0.4   0.5   0.6  ...  0.40  \\\n",
      "0  0.21  0.28    0.50  0.0  0.14  0.28  0.21  0.07  0.00  0.94  ...  0.00   \n",
      "1  0.06  0.00    0.71  0.0  1.23  0.19  0.19  0.12  0.64  0.25  ...  0.01   \n",
      "2  0.00  0.00    0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.00   \n",
      "3  0.00  0.00    0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.00   \n",
      "4  0.00  0.00    0.00  0.0  1.85  0.00  0.00  1.85  0.00  0.00  ...  0.00   \n",
      "\n",
      "    0.41  0.42  0.778   0.43   0.44  3.756   61   278  1  \n",
      "0  0.132   0.0  0.372  0.180  0.048  5.114  101  1028  1  \n",
      "1  0.143   0.0  0.276  0.184  0.010  9.821  485  2259  1  \n",
      "2  0.137   0.0  0.137  0.000  0.000  3.537   40   191  1  \n",
      "3  0.135   0.0  0.135  0.000  0.000  3.537   40   191  1  \n",
      "4  0.223   0.0  0.000  0.000  0.000  3.000   15    54  1  \n",
      "\n",
      "[5 rows x 58 columns]\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('spambase.data')\n",
    "datanames = open('spambase.names', 'r')\n",
    "print(dataset.head())\n",
    "num_attr = dataset.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0\n",
       "0.64      0\n",
       "0.64.1    0\n",
       "0.1       0\n",
       "0.32      0\n",
       "0.2       0\n",
       "0.3       0\n",
       "0.4       0\n",
       "0.5       0\n",
       "0.6       0\n",
       "0.7       0\n",
       "0.64.2    0\n",
       "0.8       0\n",
       "0.9       0\n",
       "0.10      0\n",
       "0.32.1    0\n",
       "0.11      0\n",
       "1.29      0\n",
       "1.93      0\n",
       "0.12      0\n",
       "0.96      0\n",
       "0.13      0\n",
       "0.14      0\n",
       "0.15      0\n",
       "0.16      0\n",
       "0.17      0\n",
       "0.18      0\n",
       "0.19      0\n",
       "0.20      0\n",
       "0.21      0\n",
       "0.22      0\n",
       "0.23      0\n",
       "0.24      0\n",
       "0.25      0\n",
       "0.26      0\n",
       "0.27      0\n",
       "0.28      0\n",
       "0.29      0\n",
       "0.30      0\n",
       "0.31      0\n",
       "0.32.2    0\n",
       "0.33      0\n",
       "0.34      0\n",
       "0.35      0\n",
       "0.36      0\n",
       "0.37      0\n",
       "0.38      0\n",
       "0.39      0\n",
       "0.40      0\n",
       "0.41      0\n",
       "0.42      0\n",
       "0.778     0\n",
       "0.43      0\n",
       "0.44      0\n",
       "3.756     0\n",
       "61        0\n",
       "278       0\n",
       "1         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check how many null values in data\n",
    "dataset.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title Attributes\n",
    "This section is probably not necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['word_freq_make:', 'word_freq_address:', 'word_freq_all:', 'word_freq_3d:', 'word_freq_our:', 'word_freq_over:', 'word_freq_remove:', 'word_freq_internet:', 'word_freq_order:', 'word_freq_mail:', 'word_freq_receive:', 'word_freq_will:', 'word_freq_people:', 'word_freq_report:', 'word_freq_addresses:', 'word_freq_free:', 'word_freq_business:', 'word_freq_email:', 'word_freq_you:', 'word_freq_credit:', 'word_freq_your:', 'word_freq_font:', 'word_freq_000:', 'word_freq_money:', 'word_freq_hp:', 'word_freq_hpl:', 'word_freq_george:', 'word_freq_650:', 'word_freq_lab:', 'word_freq_labs:', 'word_freq_telnet:', 'word_freq_857:', 'word_freq_data:', 'word_freq_415:', 'word_freq_85:', 'word_freq_technology:', 'word_freq_1999:', 'word_freq_parts:', 'word_freq_pm:', 'word_freq_direct:', 'word_freq_cs:', 'word_freq_meeting:', 'word_freq_original:', 'word_freq_project:', 'word_freq_re:', 'word_freq_edu:', 'word_freq_table:', 'word_freq_conference:', 'char_freq_;:', 'char_freq_(:', 'char_freq_[:', 'char_freq_!:', 'char_freq_$:', 'char_freq_#:', 'capital_run_length_average:', 'capital_run_length_longest:', 'capital_run_length_total:', 'is_spam:']\n",
      "58\n"
     ]
    }
   ],
   "source": [
    "# extracting keys for each column of the data\n",
    "keys = []\n",
    "\n",
    "for line in datanames:\n",
    "    line = re.match(r\"^(word|char|cap)\",line)\n",
    "    if line:\n",
    "        line = line.string # convert back into string\n",
    "        attribute = re.split(r'\\s+', line)[0]\n",
    "        keys.append(attribute)\n",
    "\n",
    "\n",
    "# last attribute is whether email is spam or not\n",
    "keys.append(\"is_spam:\")\n",
    "\n",
    "# attach keys to data set\n",
    "labelled_dataset = np.vstack((keys,dataset))\n",
    "\n",
    "print(keys)\n",
    "print(len(keys))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data into training data and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['0.21' '0.28' '0.5' ... '5.114' '101.0' '1028.0']\n",
      " ['0.06' '0.0' '0.71' ... '9.821' '485.0' '2259.0']\n",
      " ['0.0' '0.0' '0.0' ... '3.537' '40.0' '191.0']\n",
      " ...\n",
      " ['0.3' '0.0' '0.3' ... '1.4040000000000001' '6.0' '118.0']\n",
      " ['0.96' '0.0' '0.0' ... '1.147' '5.0' '78.0']\n",
      " ['0.0' '0.0' '0.65' ... '1.25' '5.0' '40.0']]\n"
     ]
    }
   ],
   "source": [
    "# seperate features from result\n",
    "X = labelled_dataset[1:,:57] #\n",
    "y = labelled_dataset[1:,57] # this is a binary array \n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['0.0' '0.0' '0.0' ... '5.5' '10.0' '11.0']\n",
      " ['0.0' '0.0' '0.0' ... '3.95' '23.0' '79.0']\n",
      " ['0.0' '0.0' '0.0' ... '1.526' '7.0' '87.0']\n",
      " ...\n",
      " ['0.0' '14.28' '0.0' ... '1.8' '5.0' '9.0']\n",
      " ['0.0' '0.0' '0.0' ... '1.058' '2.0' '18.0']\n",
      " ['0.14' '0.0' '0.28' ... '1.867' '14.0' '521.0']]\n",
      "['0.0' '1.0' '0.0' ... '0.0' '0.0' '1.0']\n"
     ]
    }
   ],
   "source": [
    "# Train and Test splitting of data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "print(X_train)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  using randomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0.0', '0.0', '0.0', '1.0', '0.0', '0.0', '0.0', '0.0', '0.0',\n",
       "       '0.0', '1.0', '0.0', '0.0', '1.0', '1.0', '0.0', '1.0', '1.0',\n",
       "       '1.0', '0.0'], dtype='<U32')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using randomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=30)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "pred_clf = clf.predict(X_test)\n",
    "pred_clf[:20]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.97      0.95       530\n",
      "         1.0       0.95      0.90      0.93       390\n",
      "\n",
      "    accuracy                           0.94       920\n",
      "   macro avg       0.94      0.94      0.94       920\n",
      "weighted avg       0.94      0.94      0.94       920\n",
      "\n",
      "[[513  17]\n",
      " [ 38 352]]\n"
     ]
    }
   ],
   "source": [
    "# check performance of ml model\n",
    "print(classification_report(y_test, pred_clf))\n",
    "print(confusion_matrix(y_test, pred_clf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0.0', '1.0', '0.0', '1.0', '0.0', '0.0', '0.0', '0.0', '0.0',\n",
       "       '0.0', '1.0', '1.0', '0.0', '1.0', '1.0', '0.0', '1.0', '1.0',\n",
       "       '1.0', '0.0'], dtype='<U32')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "pred_clf = clf.predict(X_test)\n",
    "pred_clf[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.95      0.94       530\n",
      "         1.0       0.93      0.89      0.91       390\n",
      "\n",
      "    accuracy                           0.93       920\n",
      "   macro avg       0.93      0.92      0.92       920\n",
      "weighted avg       0.93      0.93      0.92       920\n",
      "\n",
      "[[502  28]\n",
      " [ 41 349]]\n"
     ]
    }
   ],
   "source": [
    "# check performance of ml model\n",
    "print(classification_report(y_test, pred_clf))\n",
    "print(confusion_matrix(y_test, pred_clf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using neural network\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0.0', '0.0', '0.0', '1.0', '0.0', '0.0', '0.0', '0.0', '0.0',\n",
       "       '1.0', '0.0', '0.0', '0.0', '1.0', '1.0', '0.0', '1.0', '1.0',\n",
       "       '1.0', '0.0'], dtype='<U3')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MLPClassifier(alpha=1e-5, hidden_layer_sizes=(num_attr, num_attr, num_attr), random_state=1)\n",
    "\n",
    "# convert X_train array into double in order to use MLPClassifier\n",
    "X_train = X_train.astype(np.float64)\n",
    "X_test = X_test.astype(np.float64)\n",
    "\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "pred_clf = clf.predict(X_test)\n",
    "pred_clf[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.90      0.91       530\n",
      "         1.0       0.86      0.89      0.88       390\n",
      "\n",
      "    accuracy                           0.89       920\n",
      "   macro avg       0.89      0.89      0.89       920\n",
      "weighted avg       0.90      0.89      0.89       920\n",
      "\n",
      "[[475  55]\n",
      " [ 42 348]]\n"
     ]
    }
   ],
   "source": [
    "# check performance of ml model\n",
    "print(classification_report(y_test, pred_clf))\n",
    "print(confusion_matrix(y_test, pred_clf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
